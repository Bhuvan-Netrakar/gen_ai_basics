{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1QFDYbrJjU0kdQafjksm1krvvteRI2V0q","authorship_tag":"ABX9TyOn63KFIFMT43oe3zS12EBB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%cd /content/drive/MyDrive/genai/con_gan"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouVazWWN8OUM","executionInfo":{"status":"ok","timestamp":1748309866270,"user_tz":-330,"elapsed":503,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"048645d8-70a5-461e-9722-73dda8ffd03a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/genai/con_gan\n"]}]},{"cell_type":"code","source":["# Create a project folder and move there\n","!mkdir cgan\n","!cd cgan\n","\n","# Create and activate a Python environment using venv\n","!python3 -m venv venv\n","!source venv/bin/activate\n","\n","# We should always upgrade pip as it's usually old version\n","# that has older information about libraries\n","!pip install --upgrade pip\n","\n","# We install required libraries under the virtual environment\n","!pip install torch torchvision matplotlib tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZLXCzYF7vf_","executionInfo":{"status":"ok","timestamp":1748307382903,"user_tz":-330,"elapsed":101300,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"0e33738c-3074-45bf-b646-8065112598d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘cgan’: File exists\n","Error: Command '['/content/drive/MyDrive/genai/con_gan/venv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n","/bin/bash: line 1: venv/bin/activate: No such file or directory\n","Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n","Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-25.1.1\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m185.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m192.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m140.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n","\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n","\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n","\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n","\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n","\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n","\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n","\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n","\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n","\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [nvidia-cusolver-cu12]\n","\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YCnDIjH7X2h","executionInfo":{"status":"ok","timestamp":1748307499906,"user_tz":-330,"elapsed":52,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"ba369c28-cffe-4ca3-ee88-5c5555e8e1ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","# Labels (i.e., 1 and 3)\n","labels = torch.LongTensor([1, 3])\n","\n","# Create one-hot encoded labels\n","encoded = F.one_hot(labels, num_classes=10)\n","\n","print(encoded)"]},{"cell_type":"code","source":["# Coverts conditions into feature vectors\n","class Condition(nn.Module):\n","    def __init__(self, alpha: float):\n","        super().__init__()\n","\n","        # From one-hot encoding to features: 10 => 784\n","        self.fc = nn.Sequential(\n","            nn.Linear(10, 784),\n","            nn.BatchNorm1d(784),\n","            nn.LeakyReLU(alpha))\n","\n","    def forward(self, labels: torch.Tensor):\n","        # One-hot encode labels\n","        x = F.one_hot(labels, num_classes=10)\n","\n","        # From Long to Float\n","        x = x.float()\n","\n","        # To feature vectors\n","        return self.fc(x)"],"metadata":{"id":"oCDzU-lv7hUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reshape helper\n","class Reshape(nn.Module):\n","    def __init__(self, *shape):\n","        super().__init__()\n","\n","        self.shape = shape\n","\n","    def forward(self, x):\n","        return x.reshape(-1, *self.shape)"],"metadata":{"id":"_kR60EHk7nDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generator network\n","class Generator(nn.Module):\n","    def __init__(self, sample_size: int, alpha: float):\n","        super().__init__()\n","\n","        # sample_size => 784\n","        self.fc = nn.Sequential(\n","            nn.Linear(sample_size, 784),\n","            nn.BatchNorm1d(784),\n","            nn.LeakyReLU(alpha))\n","\n","        # 784 => 16 x 7 x 7\n","        self.reshape = Reshape(16, 7, 7)\n","\n","        # 16 x 7 x 7 => 32 x 14 x 14\n","        self.conv1 = nn.Sequential(\n","            nn.ConvTranspose2d(16, 32,\n","                               kernel_size=5, stride=2, padding=2,\n","                               output_padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(alpha))\n","\n","        # 32 x 14 x 14 => 1 x 28 x 28\n","        self.conv2 = nn.Sequential(\n","            nn.ConvTranspose2d(32, 1,\n","                               kernel_size=5, stride=2, padding=2,\n","                               output_padding=1, bias=False),\n","            nn.Sigmoid())\n","\n","        # Random value sample size\n","        self.sample_size = sample_size\n","\n","        # To convert labels into feature vectors\n","        self.cond = Condition(alpha)\n","\n","    def forward(self, labels: torch.Tensor):\n","        # Labels as feature vectors\n","        c = self.cond(labels)\n","\n","        # Batch size is the number of labels\n","        batch_size = len(labels)\n","\n","        # Generate random inputs\n","        z = torch.randn(batch_size, self.sample_size)\n","\n","        # Inputs are the sum of random inputs and label features\n","        x = self.fc(z)        # => 784\n","        x = self.reshape(x+c) # => 16 x 7 x 7\n","        x = self.conv1(x)     # => 32 x 14 x 14\n","        x = self.conv2(x)     # => 1 x 28 x 28\n","        return x"],"metadata":{"id":"aZ_MNUnl9M7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c = self.cond(labels)\n","z = torch.randn(batch_size, self.sample_size)\n","x = self.fc(z)\n","x = self.reshape(x+c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"YrSLLla2_Alo","executionInfo":{"status":"error","timestamp":1748307524525,"user_tz":-330,"elapsed":86,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"5b431703-17bd-45be-bc8f-cd293a848d37"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'self' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-7ce4e8e3a5d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"]}]},{"cell_type":"code","source":["# Label feature vectors (784)\n","c = self.cond(labels)\n","\n","# Random value vectors (784)\n","z = torch.randn(batch_size, self.sample_size)\n","x = self.fc(z)\n","\n","# Element-wise addition and reshape from 784 into 16x7x7\n","x = self.reshape(x+c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"DBQXdO08-7W_","executionInfo":{"status":"error","timestamp":1748307577550,"user_tz":-330,"elapsed":43,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"87572593-f053-40b5-9dba-cac9fa768094"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'self' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-f8880a6ba063>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Label feature vectors (784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Random value vectors (784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"]}]},{"cell_type":"code","source":["# Create an instance of the Generator\n","# Assuming a sample_size of 100 and alpha of 0.01 for demonstration\n","generator = Generator(sample_size=100, alpha=0.01)\n","\n","# Call the forward method with the labels\n","output = generator(labels)\n","\n","# You can optionally print the output to see the generated images\n","print(output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yycpunhk9nhH","executionInfo":{"status":"ok","timestamp":1748307580771,"user_tz":-330,"elapsed":13,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"867ed06a-95b3-4cb0-c171-aa775930d8bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 28, 28])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c34c9d32","executionInfo":{"status":"ok","timestamp":1748307530927,"user_tz":-330,"elapsed":6,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"498b9eaf-a3f7-4277-de42-29de515f9c66"},"source":["# Create an instance of the Generator\n","# Assuming a sample_size of 100 and alpha of 0.01 for demonstration\n","generator = Generator(sample_size=100, alpha=0.01)\n","\n","# Call the forward method with the labels\n","output = generator(labels)\n","\n","# You can optionally print the output to see the generated images\n","print(output.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 28, 28])\n"]}]},{"cell_type":"code","source":["# Discriminator network\n","class Discriminator(nn.Module):\n","    def __init__(self, alpha: float):\n","        super().__init__()\n","\n","        # 1 x 28 x 28 => 32 x 14 x 14\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 32,\n","                      kernel_size=5, stride=2, padding=2, bias=False),\n","            nn.LeakyReLU(alpha))\n","\n","        # 32 x 14 x 14 => 16 x 7 x 7\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(32, 16,\n","                      kernel_size=5, stride=2, padding=2, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(alpha))\n","\n","        # 16 x 7 x 7 => 784\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(784, 784),\n","            nn.BatchNorm1d(784),\n","            nn.LeakyReLU(alpha),\n","            nn.Linear(784, 1))\n","\n","        # Reshape label features: 784 => 16 x 7 x 7\n","        self.cond = nn.Sequential(\n","            Condition(alpha),\n","            Reshape(16, 7, 7))\n","\n","    def forward(self, images: torch.Tensor,\n","                      labels: torch.Tensor,\n","                      targets: torch.Tensor):\n","        # Label features\n","        c = self.cond(labels)\n","\n","        # Image features + Label features => real or fake?\n","        x = self.conv1(images)    # => 32 x 14 x 14\n","        x = self.conv2(x)         # => 16 x 7 x 7\n","        prediction = self.fc(x+c) # => 1\n","\n","        loss = F.binary_cross_entropy_with_logits(prediction, targets)\n","        return loss"],"metadata":{"id":"nj_vzoPbQMPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train loop\n","from tqdm import tqdm\n","for epoch in range(100):\n","\n","    d_losses = []\n","    g_losses = []\n","\n","    for images, labels in tqdm(dataloader):\n","\n","        #===============================\n","        # Disciminator Network Training\n","        #===============================\n","\n","        # Get the actual batch size\n","        batch_size = images.size(0)\n","\n","        # Define target tensors for real and fake labels for the current batch\n","        real_targets = torch.ones(batch_size, 1)\n","        fake_targets = torch.zeros(batch_size, 1)\n","\n","        # Images from MNIST are considered as real\n","        d_loss = discriminator(images, labels, real_targets)\n","\n","        # Images from Generator are considered as fake\n","        d_loss += discriminator(generator(labels), labels, fake_targets)\n","\n","        # Discriminator paramter update\n","        d_optimizer.zero_grad()\n","        d_loss.backward()\n","        d_optimizer.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"xDx4l4k5QToj","executionInfo":{"status":"error","timestamp":1748307987473,"user_tz":-330,"elapsed":89831,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"cfa1ac26-7b1c-4a5d-ea53-7249d08cc772"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [01:13<00:00, 12.73it/s]\n"," 21%|██▏       | 201/938 [00:15<00:57, 12.73it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-1a21238ed053>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mg_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#===============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"021b388b","executionInfo":{"status":"ok","timestamp":1748307695125,"user_tz":-330,"elapsed":10569,"user":{"displayName":"01fe23bec434","userId":"06324811767717257557"}},"outputId":"beb6f805-6017-4e97-e2f0-aa373bf181c8"},"source":["import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","# Define transformations to apply to the images\n","transform = transforms.Compose([\n","    transforms.ToTensor(), # Convert images to PyTorch tensors\n","])\n","\n","# Load the MNIST training dataset\n","train_dataset = torchvision.datasets.MNIST(root='./data',\n","                                           train=True,\n","                                           download=True,\n","                                           transform=transform)\n","\n","# Create a DataLoader for the training dataset\n","batch_size = 64 # You can adjust the batch size\n","dataloader = DataLoader(train_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=True)\n","\n","print(\"MNIST dataset loaded and DataLoader created.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 11.8MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 369kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 3.18MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 5.94MB/s]"]},{"output_type":"stream","name":"stdout","text":["MNIST dataset loaded and DataLoader created.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"a89245fe"},"source":["# Initialize Generator and Discriminator\n","generator = Generator(sample_size=100, alpha=0.01) # Assuming sample_size and alpha as before\n","discriminator = Discriminator(alpha=0.01) # Assuming alpha as before\n","\n","# Define target tensors for real and fake labels\n","real_targets = torch.ones(batch_size, 1)\n","fake_targets = torch.zeros(batch_size, 1)\n","\n","# Define optimizers\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # We'll need this for the generator later"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.utils import make_grid\n","from tqdm import tqdm\n","\n","# Common config\n","batch_size  = 64\n","\n","# Generator config\n","sample_size = 100    # Random sample size\n","g_alpha     = 0.01   # LeakyReLU alpha\n","g_lr        = 1.0e-4 # Learning rate\n","\n","# Discriminator config\n","d_alpha     = 0.01   # LeakyReLU alpha\n","d_lr        = 1.0e-4 # Learning rate\n","\n","# Data Loader for MNIST\n","transform = transforms.ToTensor()\n","dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True)\n","\n","# Coverts conditions into feature vectors\n","class Condition(nn.Module):\n","    def __init__(self, alpha: float):\n","        super().__init__()\n","\n","        # From one-hot encoding to features: 10 => 784\n","        self.fc = nn.Sequential(\n","            nn.Linear(10, 784),\n","            nn.BatchNorm1d(784),\n","            nn.LeakyReLU(alpha))\n","\n","    def forward(self, labels: torch.Tensor):\n","        # One-hot encode labels\n","        x = F.one_hot(labels, num_classes=10)\n","\n","        # From Long to Float\n","        x = x.float()\n","\n","        # To feature vectors\n","        return self.fc(x)\n","\n","# Reshape helper\n","class Reshape(nn.Module):\n","    def __init__(self, *shape):\n","        super().__init__()\n","\n","        self.shape = shape\n","\n","    def forward(self, x):\n","        return x.reshape(-1, *self.shape)\n","\n","# Generator network\n","class Generator(nn.Module):\n","    def __init__(self, sample_size: int, alpha: float):\n","        super().__init__()\n","\n","        # sample_size => 784\n","        self.fc = nn.Sequential(\n","            nn.Linear(sample_size, 784),\n","            nn.BatchNorm1d(784),\n","            nn.LeakyReLU(alpha))\n","\n","        # 784 => 16 x 7 x 7\n","        self.reshape = Reshape(16, 7, 7)\n","\n","        # 16 x 7 x 7 => 32 x 14 x 14\n","        self.conv1 = nn.Sequential(\n","            nn.ConvTranspose2d(16, 32,\n","                               kernel_size=5, stride=2, padding=2,\n","                               output_padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(alpha))\n","\n","        # 32 x 14 x 14 => 1 x 28 x 28\n","        self.conv2 = nn.Sequential(\n","            nn.ConvTranspose2d(32, 1,\n","                               kernel_size=5, stride=2, padding=2,\n","                               output_padding=1, bias=False),\n","            nn.Sigmoid())\n","\n","        # Random value sample size\n","        self.sample_size = sample_size\n","\n","        # To convert labels into feature vectors\n","        self.cond = Condition(alpha)\n","\n","    def forward(self, labels: torch.Tensor):\n","        # Labels as feature vectors\n","        c = self.cond(labels)\n","\n","        # Batch size is the number of labels\n","        batch_size = len(labels)\n","\n","        # Generate random inputs\n","        z = torch.randn(batch_size, self.sample_size)\n","\n","        # Inputs are the sum of random inputs and label features\n","        x = self.fc(z)        # => 784\n","        x = self.reshape(x+c) # => 16 x 7 x 7\n","        x = self.conv1(x)     # => 32 x 14 x 14\n","        x = self.conv2(x)     # => 1 x 28 x 28\n","        return x\n","\n","# Discriminator network\n","class Discriminator(nn.Module):\n","    def __init__(self, alpha: float):\n","        super().__init__()\n","\n","        # 1 x 28 x 28 => 32 x 14 x 14\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 32,\n","                      kernel_size=5, stride=2, padding=2, bias=False),\n","            nn.LeakyReLU(alpha))\n","\n","        # 32 x 14 x 14 => 16 x 7 x 7\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(32, 16,\n","                      kernel_size=5, stride=2, padding=2, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(alpha))\n","\n","        # 16 x 7 x 7 => 784\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(784, 784),\n","            nn.BatchNorm1d(784),\n","            nn.LeakyReLU(alpha),\n","            nn.Linear(784, 1))\n","\n","        # Reshape label features: 784 => 16 x 7 x 7\n","        self.cond = nn.Sequential(\n","            Condition(alpha),\n","            Reshape(16, 7, 7))\n","\n","    def forward(self, images: torch.Tensor,\n","                      labels: torch.Tensor,\n","                      targets: torch.Tensor):\n","        # Label features\n","        c = self.cond(labels)\n","\n","        # Image features + Label features => real or fake?\n","        x = self.conv1(images)    # => 32 x 14 x 14\n","        x = self.conv2(x)         # => 16 x 7 x 7\n","        prediction = self.fc(x+c) # => 1\n","\n","        loss = F.binary_cross_entropy_with_logits(prediction, targets)\n","        return loss\n","\n","# To save grid images\n","def save_image_grid(epoch: int, images: torch.Tensor, ncol: int):\n","    image_grid = make_grid(images, ncol)     # Into a grid\n","    image_grid = image_grid.permute(1, 2, 0) # Channel to last\n","    image_grid = image_grid.cpu().numpy()    # Into Numpy\n","\n","    plt.imshow(image_grid)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.savefig(f'generated_{epoch:03d}.jpg')\n","    plt.close()\n","\n","# Real / Fake targets\n","real_targets = torch.ones(batch_size, 1)\n","fake_targets = torch.zeros(batch_size, 1)\n","\n","# Generator and discriminator\n","generator = Generator(sample_size, g_alpha)\n","discriminator = Discriminator(d_alpha)\n","\n","# Optimizers\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr)\n","g_optimizer = torch.optim.Adam(generator.parameters(), lr=g_lr)\n","\n","# Train loop\n","for epoch in range(100):\n","\n","    d_losses = []\n","    g_losses = []\n","\n","    for images, labels in tqdm(dataloader):\n","\n","        #===============================\n","        # Disciminator Network Training\n","        #===============================\n","\n","        # Images from MNIST are considered as real\n","        d_loss = discriminator(images, labels, real_targets)\n","\n","        # Images from Generator are considered as fake\n","        d_loss += discriminator(generator(labels), labels, fake_targets)\n","\n","        # Discriminator paramter update\n","        d_optimizer.zero_grad()\n","        d_loss.backward()\n","        d_optimizer.step()\n","\n","        #===============================\n","        # Generator Network Training\n","        #===============================\n","\n","        # Images from Generator should be as real as ones from MNIST\n","        g_loss = discriminator(generator(labels), labels, real_targets)\n","\n","        # Generator parameter update\n","        g_optimizer.zero_grad()\n","        g_loss.backward()\n","        g_optimizer.step()\n","\n","        # Keep losses for logging\n","        d_losses.append(d_loss.item())\n","        g_losses.append(g_loss.item())\n","\n","    # Print loss\n","    print(epoch, np.mean(d_losses), np.mean(g_losses))\n","\n","    # Save generated images\n","    labels = torch.LongTensor(list(range(10))).repeat(8).flatten()\n","    save_image_grid(epoch, generator(labels), ncol=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_8UwpsoRo8M","outputId":"124fc7a6-a1bd-447b-9126-ae42a962cd84"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 18.2MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 487kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.56MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 6.83MB/s]\n","100%|██████████| 937/937 [02:01<00:00,  7.68it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["0 0.4963098222125429 1.7084557141158472\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.77it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["1 0.2569355297686578 2.3792391250838336\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:01<00:00,  7.71it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2 0.17819844387479628 2.813231841731606\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.80it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["3 0.15889845961026983 3.0266903645200944\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.80it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["4 0.16792171006364273 3.050145267040778\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5 0.1669741017125714 3.10327550403082\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:01<00:00,  7.72it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["6 0.16216869391858768 3.1686880087267246\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.81it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7 0.18060065294628846 3.1072985856230257\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.79it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["8 0.1799257197432228 3.135843713611778\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [01:59<00:00,  7.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["9 0.18435387411567292 3.1197136108750594\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:01<00:00,  7.74it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["10 0.1874175486110127 3.1577125598170586\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [01:59<00:00,  7.83it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["11 0.19691263835006487 3.1178593583397065\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [01:59<00:00,  7.82it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["12 0.19729078627860405 3.156176245963179\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.78it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["13 0.20933424263174785 3.113224070634506\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:05<00:00,  7.48it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["14 0.19389755192154118 3.117226991353193\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:06<00:00,  7.43it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["15 0.20002170466482957 3.2310159007920274\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:02<00:00,  7.67it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["16 0.20148196573127677 3.1738102312657976\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:00<00:00,  7.76it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["17 0.19771901885864573 3.2474424919171168\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 937/937 [02:04<00:00,  7.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["18 0.18925735747626524 3.2895487858620625\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 937/937 [02:02<00:00,  7.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["19 0.18701724355032504 3.320430235903444\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 937/937 [02:13<00:00,  7.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["20 0.17125521647160438 3.427141616922051\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 306/937 [00:46<01:15,  8.41it/s]"]}]}]}